<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta name="google-site-verification" content="ekv-W0AxllwZ-k-lfisabABgmiSU94Ex3-o0Ka-TjRU" />
<meta name="baidu-site-verification" content="PKbwImzbNH" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Machine Learning," />





  <link rel="alternate" href="/atom.xml" title="Jellyyoung's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.icon?v=5.0.2" />






<meta name="description" content="&amp;emsp;&amp;emsp;GBDT是一个应用很广泛的算法，可以用于解决分类、回归等问题。GBDT算法也有其他的名字，如MART(Multiple Additive Regression Tree)，GBRT(Gradient Boost Regression Tree)，Tree Net等。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法笔记——GBDT & XGBoost">
<meta property="og:url" content="http://yaodong.ml/machine-learning/机器学习算法笔记——GBDT-XGBoost.html">
<meta property="og:site_name" content="Jellyyoung's Blog">
<meta property="og:description" content="&amp;emsp;&amp;emsp;GBDT是一个应用很广泛的算法，可以用于解决分类、回归等问题。GBDT算法也有其他的名字，如MART(Multiple Additive Regression Tree)，GBRT(Gradient Boost Regression Tree)，Tree Net等。">
<meta property="og:updated_time" content="2017-04-13T05:30:30.932Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法笔记——GBDT & XGBoost">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;GBDT是一个应用很广泛的算法，可以用于解决分类、回归等问题。GBDT算法也有其他的名字，如MART(Multiple Additive Regression Tree)，GBRT(Gradient Boost Regression Tree)，Tree Net等。">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '6310520035420931000',
      author: '摇摇果冻'
    }
  };
</script>




  <link rel="canonical" href="http://yaodong.ml/machine-learning/机器学习算法笔记——GBDT-XGBoost.html"/>


  <title> 机器学习算法笔记——GBDT & XGBoost | Jellyyoung's Blog </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Jellyyoung's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Practice makes me progressive</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="/resume" rel="section">
            
            简历
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                机器学习算法笔记——GBDT & XGBoost
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-13T13:27:59+08:00" content="2017-02-13">
              2017-02-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/学习笔记/" itemprop="url" rel="index">
                    <span itemprop="name">学习笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/machine-learning/机器学习算法笔记——GBDT-XGBoost.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="machine-learning/机器学习算法笔记——GBDT-XGBoost.html" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/machine-learning/机器学习算法笔记——GBDT-XGBoost.html" class="leancloud_visitors" data-flag-title="机器学习算法笔记——GBDT & XGBoost">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>&emsp;&emsp;<strong>GBDT</strong>是一个应用很广泛的算法，可以用于解决分类、回归等问题。GBDT算法也有其他的名字，如MART(Multiple Additive Regression Tree)，GBRT(Gradient Boost Regression Tree)，Tree Net等。<br><a id="more"></a><br>&emsp;&emsp;GBDT的全称是Gradient Boosting Decision Tree，即梯度提升决策树。GBDT属于集成学习模型，通过将多个Decision Tree的决策结果迭代累加起来，作为最终的预测输出，进而达到提升模型性能的目的。<br>&emsp;&emsp;需要注意的是，GBDT算法过程中的树都属于回归树，不是分类树。GBDT的核心在于，每一棵子树学习的是之前所有树的预测结果与实际观测值之间的残差。Gradient Boosting就是拟合Loss function的梯度，将其作为新的弱回归树加入到总的算法中即可。</p>
<h3 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h3><p>&emsp;&emsp;首先介绍一下Gradient Boosting的基本概念。Gradient Boosting是一个框架，基于梯度提升算法的学习器叫做<strong>GBM</strong>（Gradient Boosting Machine）。<br>&emsp;&emsp;《统计学习方法》中提到，提升树算法利用加法模型和前向分步算法实现模型的优化过程。但是实际的回归问题中，模型的代价函数（Cost Function）可能不是特殊形式的平方损失函数或指数损失函数等。对于一般形式的损失函数而言，boosting算法对Cost Function的求解和优化会变得比较复杂。Gradient Boosting正是在这样的问题背景下产生，Gradient Boosting的核心思想是迭代生成$K$个具有弱泛化能力的学习器，然后将$K$个弱学习器的预测结果相加，得到最后的预测结果。Gradient Boosting框架中，后续的基学习器$f_{k+1}(x)$都是在前面的基学习器$f_k(x)$的训练效果上得到的，即</p>
<script type="math/tex; mode=display">f_{m+1}(x)=f_m(x)+h(x)</script><p>&emsp;&emsp;Gradient Boosting算法的流程如下：给定样本数据集$T={(x^{(1)},y^{(1)}),…,(x^{(i)},y^{(i)}),…,(x^{(n)},y^{(n)})}$，$x^{(i)}\in R^n$，$y(i)\in {-1,+1}$，设基学习器的数量为$M$，第$m$个基学习器的损失函数为$L(y,f_m(x))$。</p>
<ol>
<li>初始化第一课子树，估计使损失函数最小化的常数值：<script type="math/tex; mode=display">f_0(x)=\arg\min_\gamma\sum_{i=1}^{n}L(y^{(i)},\gamma)</script></li>
<li>对$m=1,2,…,M$:<br><strong>1)</strong> 对i=1,2,…,n，计算当前损失函数的负梯度在当前模型的值，作为当前模型的残差估计：<script type="math/tex; mode=display">r_{mi}=\left[\frac{\partial L(y^{(i)},f(x^{(i)}))}{\partial f(x^{(i)})}\right]_{f(x)=f_{m-1}(x)}</script><strong>2)</strong> 根据${x^{(i)},r_{mi}}$拟合回归树，生成基学习器$h_m(x)$。<br><strong>3)</strong> 计算最优的叶节点区域估计值$\gamma_m$，使损失函数最小化<script type="math/tex; mode=display">\gamma_{m}=\arg\min_\gamma\sum_{i=1}^nL(y^{(i)},f_{k-1}(x^{(i)})+\gamma h_m(x^{(i)}))</script><strong>4)</strong> 更新第$m$个子回归树模型<script type="math/tex; mode=display">f_m(x)=f_{m-1}(x)+\gamma_m h_m(x^{(i)})</script></li>
<li>组合$m$个基学习器，得到最终的模型<script type="math/tex; mode=display">\hat f(x)=\sum_{m=0}^{M}\gamma_m f(x)</script></li>
</ol>
<h4 id="GBDT算法理论推导"><a href="#GBDT算法理论推导" class="headerlink" title="GBDT算法理论推导"></a>GBDT算法理论推导</h4><p>&emsp;&emsp;Gadient Boosting Decision Tree是Gradient Boosting框架下的Decision Tree版本，基本思想是新模型是在前一个模型的损失函数的梯度下降方向建立。下面进行算法推导：<br>&emsp;&emsp;假设模型的参数空间为$P$，$P={p_1,p_2,…}$，$F(x;P)$表示以$P$为参数的关于$x$的函数，也就是GBDT的预测函数。GBDT算法属于前向加法模型，用$\beta$表示每个学习模型的权重，$\alpha$表示每个学习模型的内部参数，则有</p>
<script type="math/tex; mode=display">F(x;P)=\sum_{i=1}^{M}\beta_{m}h(x;\alpha_{m})</script><p>&emsp;&emsp;GBDT算法通过优化参数空间${\alpha,\beta}$来对最终的预测函数$F(x;P)$进行优化。在给定损失函数和训练数据的前提下，对$F(x;P)$的学习即为GBDT的损失函数极小化问题，设模型$F(x;P)$的Loss Function为$\Phi(P)$，则有</p>
<script type="math/tex; mode=display">P^{*}=\arg\min_{F}\Phi(P)</script><script type="math/tex; mode=display">F^*(x;P)=\arg\min_{F}\Phi(P)</script><p>&emsp;&emsp;模型的Loss Function为$\Phi(P)$</p>
<script type="math/tex; mode=display">\Phi(P)=E_{y,x}L(y,F(x;P))=E_{x}[E_{y}(L(y,F(x)))\mid \boldsymbol{x}]</script><p>&emsp;&emsp;基于模型的可加性，有如下推导关系</p>
<script type="math/tex; mode=display">F^{*}(\boldsymbol{x})=\sum_{i=1}^{M}f(\boldsymbol{x})</script><script type="math/tex; mode=display">P^{*}=\sum_{i=1}^{M}p_{m}</script><p>&emsp;&emsp;因此，对损失函数$\Phi(P)$在当前模型$F_{m-1}(\boldsymbol{x})$下求偏导，得到梯度：</p>
<script type="math/tex; mode=display">g_{m}(\boldsymbol{x})=\big{[}\frac{\partial{\Phi(F(\boldsymbol{x}))}}{\partial{F(\boldsymbol{x}})}\big{]}_{F(\boldsymbol{x})=F_{m-1}(\boldsymbol{x})}</script><p>&emsp;&emsp;$F_{m-1}(\boldsymbol{x})$表示前$m-1$个基学习模型的累加：</p>
<script type="math/tex; mode=display">F_{m-1}(\boldsymbol{x})=\sum_{i=1}^{m-1}f_{i}(\boldsymbol{x})</script><p>&emsp;&emsp;第$m$个基学习模型的预测函数$f_{m}(\boldsymbol{x})$的计算公式如下：</p>
<script type="math/tex; mode=display">f_{m}(\boldsymbol{x})=-\rho_{m}g_{m}(\boldsymbol{x})</script><p>&emsp;&emsp;$\rho_{m}$表示第$m$个基学习模型在当前梯度方向上下降的距离，根据损失函数与当前模型的梯度方向可求得：</p>
<script type="math/tex; mode=display">\rho_{m}=\arg\min_{\rho}\big{[}\Phi(P_{m-1}-\rho g_{m}(x))\big{]}</script><script type="math/tex; mode=display">\rho_{m}=\arg\min_{\rho}\big{[}E_{y,x}L(y,F_{m-1}(\boldsymbol{x}))-\rho g_{m}(x)\big{]}</script><p>&emsp;&emsp;GBDT的基本思路是，先训练一个回归树，并计算各样本的目标值与预测值之间的残差，将这个残差作为目标值，训练下一个回归树，继续求残差，直到回归树的数目达到指定值或残差达到允许范围，停止学习。</p>
<p>&emsp;&emsp;回忆一下原始的Boosting算法：算法初始状态下，为每一个样本赋上大小相等的权重值。在之后迭代的每一步中增加被误分类的样本的权重，减少正确分类的样本的权重，使得被误分类的样本被赋上一个很高的权重。进行M次迭代训练，将得到$M$个基学习器，最后将这$M$个根据指定的策略组合起来，即得到最终的模型。</p>
<p>&emsp;&emsp;<strong>Gradient Boost与传统的Boosting的区别</strong></p>
<ol>
<li>Gradient Boot算法在迭代的每一步都是建立一个能使损失函数沿着负梯度方向降低的学习器来弥补之前的学习器的不足。经典的AdaBoosting算法只能处理采用指数损失函数的二分类问题，但由于Gradient Boosting框架可以设置不同的可微损失函数，因此Gradient Boosting算法可以应用到不同的学习任务中；</li>
<li>AdaBoosting算法对异常点（outlier）比较敏感，但是Gradient Boosting算法可以通过引入Bagging思想、加入正则化项等方法抵御训练数据中的噪声，具有更好的健壮性。</li>
</ol>
<p>每次的计算是为了减小上一次的残差（residual）。为了消除残差，可以取损失函数的负梯度在当前模型上的取值作为当前残差的近似值，并拟合下一个子树模型。所以说，在Gradient Boost中，每个新子树模型的建立会使之前模型的残差往梯度方向减少，与传统Boosting算法对正确、错误的样本进行加权有着很大的区别。</p>
<hr>
<h3 id="梯度上升决策树算法（Gradient-Boosting-Decision-Tree，GBDT）"><a href="#梯度上升决策树算法（Gradient-Boosting-Decision-Tree，GBDT）" class="headerlink" title="梯度上升决策树算法（Gradient Boosting Decision Tree，GBDT）"></a>梯度上升决策树算法（Gradient Boosting Decision Tree，GBDT）</h3><blockquote>
<p><strong>GBDT</strong>是一个应用很广泛的算法，可以用于解决分类、回归等问题。GBDT算法也有其他的名字，如MART(Multiple Additive Regression Tree)，GBRT(Gradient Boost Regression Tree)，Tree Net等。</p>
</blockquote>
<p>&emsp;&emsp;首先介绍一下Gradient Boosting的基本概念。Gradient Boost其实是一个框架，可以套入很多不同的算法以对穿传统的机器学习算法进行改进。当损失函数不是平方损失函数或者指数损失函数，而是一般函数时，boost算法对损失函数的求解和优化会变得比较复杂，针对这一问题，学者提出了Gradient Boosting算法。核心思想是利用损失函数的负梯度在当前模型下的取值作为残差的近似，进一步训练得到下一棵回归树。<br>&emsp;&emsp;回忆一下原始的Boosting算法：算法初始状态下，为每一个样本赋上大小相等的权重值。在之后迭代的每一步中增加被误分类的样本的权重，减少正确分类的样本的权重，使得被误分类的样本被赋上一个很高的权重。进行M次迭代训练，将得到M个基学习器，最后将它们根据指定的策略组合起来，得到一个最终的模型。<br>&emsp;&emsp;GBDT中的树都是回归树，不是分类树，但是对GBDT模型调整后可以用于分类问题。GBDT的核心在于，每一棵子树学习的是之前所有树的预测结果与实际观测值之间的残差。Gradient Boosting就是拟合Loss function的梯度，将其作为新的弱回归树加入到总的算法中即可。<br>&emsp;&emsp;Gradient Boost与传统的Boost的区别是，Gradient Boot算法每次的计算是为了减小上一次的残差（residual）。为了消除残差，可以取损失函数的负梯度在当前模型上的取值作为当前残差的近似值，并拟合下一个子树模型。所以说，在Gradient Boost中，每个新子树模型的建立会使之前模型的残差往梯度方向减少，与传统Boosting算法对正确、错误的样本进行加权有着很大的区别。</p>
<p>&emsp;&emsp;GBDT的算法流程如下：给定样本数据集$T={(x^{(1)},y^{(1)}),…,(x^{(i)},y^{(i)}),…,(x^{(m)},y^{(m)})}$，$x^{(i)}\in R^n$，$y(i)\in {-1,+1}$，损失函数为$L(y,f(x))$，设生成的子树的数目是K。</p>
<ol>
<li>初始化第一课子树，估计使损失函数最小化的常数值，建立只有一个根结点的树：<script type="math/tex; mode=display">f_0(x)=\arg\min_c\sum_{i=1}^{m}L(y^{(i)},c)</script></li>
<li>对k=1,2,…,K:<br><strong>1)</strong> 对i=1,2,…,m，计算当前损失函数的负梯度在当前模型的值，作为模型残差的估计：<script type="math/tex; mode=display">g_{ki}=\left[\frac{\partial L(y^{(i)},f(x^{(i)}))}{\partial f(x^{(i)})}\right]_{f(x)=f_{k-1}(x)}</script><strong>2)</strong> 根据$r<em>{ki}$拟合一个回归树，作为下一个子树模型，估计回归树的叶节点对区域$R</em>{kj}$,$j=1,2,…,J$，以拟合残差的近似值：<br><strong>3)</strong> 利用线性搜索估计叶节点区域的值，使损失函数最小化。对$j=1,2,…,J$，计算<script type="math/tex; mode=display">c_{mj}=\arg\min_c\sum_{x_i \in R_{kj}}L(y^{(i)},f_{k-1}(x^{(i)})+c)</script><strong>4)</strong> 更新第k个子回归树模型<script type="math/tex; mode=display">f_k(x)=f_{k-1}(x)+\sum_{j=1}^Jc_{kj}I(x\in R_{kj})</script></li>
<li>得到回归树<script type="math/tex; mode=display">\hat f(x)=f_{K}(x)=\sum_{k=1}^{K}\sum_{j=1}^Jc_{kj}I(x\in R_{kj})</script></li>
</ol>
<h4 id="GBDT的优缺点"><a href="#GBDT的优缺点" class="headerlink" title="GBDT的优缺点"></a>GBDT的优缺点</h4><ul>
<li><strong>优点</strong>：GBDT中的非线性变化很多，因此模型的表达能力强，不需要做复杂的特征工程和特征变换。</li>
<li><strong>缺点</strong>：GBDT中的Boosting迭代过程是一个串行工程，不利于并行实现；此外，GBDT的计算复杂度很高。<h4 id="GBDT的参数调优"><a href="#GBDT的参数调优" class="headerlink" title="GBDT的参数调优"></a>GBDT的参数调优</h4>&emsp;&emsp;GBDT的常用参数如下：</li>
<li>子树的棵数，即基学习器的数量</li>
<li>树的深度</li>
<li>缩放因子</li>
<li>损失函数</li>
<li>数据采样比</li>
<li>特征采样比</li>
</ul>
<h3 id="Xgboost"><a href="#Xgboost" class="headerlink" title="Xgboost"></a>Xgboost</h3><p>&emsp;&emsp;XGBoost的全称是eXtreme Gradient Boosting，是Gradient Boosting算法的高效实现。XGBoost中的基学习器除了可以是CART也可以是其他线性分类器。<br>&emsp;&emsp;XGBoost的目标函数中显式的加入正则化项，当基学习器为CART时，正则化项与树的叶子结点的数量$T$、叶子结点的取值有关。<br>&emsp;&emsp;待整理。</p>
<h3 id="Xgboost与GBDT的区别："><a href="#Xgboost与GBDT的区别：" class="headerlink" title="Xgboost与GBDT的区别："></a>Xgboost与GBDT的区别：</h3><ol>
<li>传统的GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。</li>
<li>关于优化求解问题：传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。</li>
<li>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性</li>
<li>列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。</li>
<li>对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。</li>
<li>xgboost工具支持并行。<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3></li>
<li><a href="http://blog.csdn.net/puqutogether/article/details/41957089" target="_blank" rel="external">http://blog.csdn.net/puqutogether/article/details/41957089</a></li>
<li><a href="http://blog.csdn.net/china1000/article/details/51106856" target="_blank" rel="external">http://blog.csdn.net/china1000/article/details/51106856</a></li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>感谢果冻君，受益匪浅！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/wechat-qrd.png" alt="摇摇果冻 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipay-qcode.jpg" alt="摇摇果冻 Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag">#Machine Learning</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/machine-learning/机器学习算法笔记——概率图模型（Probabilistic-Graphical-Model）.html" rel="next" title="机器学习算法笔记——概率图模型（Probabilistic Graphical Model）">
                <i class="fa fa-chevron-left"></i> 机器学习算法笔记——概率图模型（Probabilistic Graphical Model）
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/machine-learning/机器学习算法笔记——随机森林（Random-Forest）.html" rel="prev" title="机器学习算法笔记——随机森林（Random Forest）">
                机器学习算法笔记——随机森林（Random Forest） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <div class="ds-share flat" data-thread-key="machine-learning/机器学习算法笔记——GBDT-XGBoost.html"
     data-title="机器学习算法笔记——GBDT & XGBoost"
     data-content=""
     data-url="http://yaodong.ml/machine-learning/机器学习算法笔记——GBDT-XGBoost.html">
  <div class="ds-share-inline">
    <ul  class="ds-share-icons-16">

      <li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
      <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
      <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
      <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
      <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>

    </ul>
    <div class="ds-share-icons-more">
    </div>
  </div>
</div>
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="machine-learning/机器学习算法笔记——GBDT-XGBoost.html"
           data-title="机器学习算法笔记——GBDT & XGBoost" data-url="http://yaodong.ml/machine-learning/机器学习算法笔记——GBDT-XGBoost.html">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/don't-fear.jpg"
               alt="摇摇果冻" />
          <p class="site-author-name" itemprop="name">摇摇果冻</p>
          <p class="site-description motion-element" itemprop="description">Nothing but practice</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">30</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/jellyyoung" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/2685489433" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/people/yao-yao-guo-dong" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com" title="Github" target="_blank">Github</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://leetcode.com" title="Leetcode" target="_blank">Leetcode</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.nowcoder.com" title="牛客网" target="_blank">牛客网</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.kaggle.com/competitions" title="Kaggle" target="_blank">Kaggle</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Boosting"><span class="nav-number">1.</span> <span class="nav-text">Gradient Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GBDT算法理论推导"><span class="nav-number">1.1.</span> <span class="nav-text">GBDT算法理论推导</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度上升决策树算法（Gradient-Boosting-Decision-Tree，GBDT）"><span class="nav-number">2.</span> <span class="nav-text">梯度上升决策树算法（Gradient Boosting Decision Tree，GBDT）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GBDT的优缺点"><span class="nav-number">2.1.</span> <span class="nav-text">GBDT的优缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GBDT的参数调优"><span class="nav-number">2.2.</span> <span class="nav-text">GBDT的参数调优</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Xgboost"><span class="nav-number">3.</span> <span class="nav-text">Xgboost</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Xgboost与GBDT的区别："><span class="nav-number">4.</span> <span class="nav-text">Xgboost与GBDT的区别：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考链接"><span class="nav-number">5.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">摇摇果冻</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"jellyyoung"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("FMr7sWjQxkJp3Cryj0InKhSH-gzGzoHsz", "MM5zwP9a10uxjJHqpLRtlyQF");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  


</body>
</html>
